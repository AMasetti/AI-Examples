{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Class\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/amasetti/AI-Portfolio-Examples/blob/master/1.%20Perceptron/main.ipynb)\n",
    "\n",
    "The perceptron model is a fundamental algorithm in machine learning and artificial neural networks. It is a binary classifier that takes in an input vector and produces a binary output based on a set of weights and a bias.\n",
    "\n",
    "Here's a brief explanation of how the perceptron model works:\n",
    "\n",
    "Input: The perceptron model takes an input vector x = (x1, x2, ..., xn), where each xi represents a feature or attribute of the input.\n",
    "\n",
    "Weighted sum: Each input feature xi is multiplied by a corresponding weight wi. These weighted inputs are summed up with a bias term b, resulting in a weighted sum: z = w1x1 + w2x2 + ... + wn*xn + b.\n",
    "\n",
    "Activation function: The weighted sum z is passed through an activation function (typically a step function or a sigmoid function) to determine the output of the perceptron. The activation function introduces non-linearity into the model.\n",
    "\n",
    "Output: The output of the perceptron is a binary value based on the result of the activation function. For example, if the activation function is a step function, the output is 1 if the weighted sum is above a threshold, and 0 otherwise.\n",
    "\n",
    "Training: The perceptron model is trained by adjusting the weights and bias based on a training dataset. Initially, the weights and bias are assigned random values. During training, the model iteratively updates the weights and bias to minimize the error between the predicted output and the true output. This process is often done using a learning algorithm called the perceptron learning rule, which adjusts the weights based on the errors made by the model.\n",
    "\n",
    "Convergence: The perceptron model continues to update the weights and bias until it reaches a point where it can accurately classify the training data or until a stopping criterion is met. The stopping criterion could be a maximum number of iterations or reaching a predefined level of accuracy.\n",
    "\n",
    "The perceptron model is a building block for more complex neural network architectures. While it is a simple and linear classifier, it has played a significant role in the development of neural networks and paved the way for more advanced models such as multi-layer perceptrons and deep neural networks.\n",
    "\n",
    " <img src=\"img/perceptron.png\" alt=\"Perceptron Model\" width=\"500\" /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, learning_rate, epochs):\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    # heaviside activation function\n",
    "    def activation(self, z):\n",
    "        return np.heaviside(z, 0) # haviside(z) heaviside -> activation\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        # Initializing weights and bias\n",
    "        self.weights = np.zeros((n_features))\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Iterating until the number of epochs\n",
    "        for epoch in range(self.epochs):\n",
    "            \n",
    "            # Traversing through the entire training set\n",
    "            for i in range(len(X)):\n",
    "                z = np.dot(X, self.weights) + self.bias # Finding the dot product and adding the bias\n",
    "                y_pred = self.activation(z) # Passing through an activation function\n",
    "                \n",
    "                #Updating weights and bias\n",
    "                self.weights = self.weights + self.learning_rate * (y[i] - y_pred[i]) * X[i]\n",
    "                self.bias = self.bias + self.learning_rate * (y[i] - y_pred[i])\n",
    "                \n",
    "        return self.weights, self.bias\n",
    "    \n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        return self.activation(z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and splitting the Dataset\n",
    "\n",
    "The Iris dataset is a well-known dataset in the field of machine learning and statistics. The dataset consists of measurements of different attributes of iris flowers belonging to three different species: setosa, versicolor, and virginica. Each flower sample is labeled with the corresponding species. The dataset contains 150 samples, with 50 samples for each species.\n",
    "\n",
    "The attributes or features of the iris flowers included in the dataset are:\n",
    "\n",
    "1. Sepal length (in centimeters)\n",
    "2. Sepal width (in centimeters)\n",
    "3. Petal length (in centimeters)\n",
    "4. Petal width (in centimeters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris() \n",
    "\n",
    "X = iris.data[:, (0, 1)] # petal length, petal width\n",
    "y = (iris.target == 0).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "143                6.8               3.2                5.9               2.3   \n",
       "123                6.3               2.7                4.9               1.8   \n",
       "124                6.7               3.3                5.7               2.1   \n",
       "114                5.8               2.8                5.1               2.4   \n",
       "15                 5.7               4.4                1.5               0.4   \n",
       "115                6.4               3.2                5.3               2.3   \n",
       "53                 5.5               2.3                4.0               1.3   \n",
       "98                 5.1               2.5                3.0               1.1   \n",
       "60                 5.0               2.0                3.5               1.0   \n",
       "93                 5.0               2.3                3.3               1.0   \n",
       "\n",
       "     target     species  \n",
       "143     2.0   virginica  \n",
       "123     2.0   virginica  \n",
       "124     2.0   virginica  \n",
       "114     2.0   virginica  \n",
       "15      0.0      setosa  \n",
       "115     2.0   virginica  \n",
       "53      1.0  versicolor  \n",
       "98      1.0  versicolor  \n",
       "60      1.0  versicolor  \n",
       "93      1.0  versicolor  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = pd.DataFrame(\n",
    "    data= np.c_[iris['data'], iris['target']],\n",
    "    columns= iris['feature_names'] + ['target']\n",
    "    )\n",
    "\n",
    "species = []\n",
    "\n",
    "for i in range(len(iris['target'])):\n",
    "    if iris['target'][i] == 0:\n",
    "        species.append(\"setosa\")\n",
    "    elif iris['target'][i] == 1:\n",
    "        species.append('versicolor')\n",
    "    else:\n",
    "        species.append('virginica')\n",
    "\n",
    "\n",
    "iris['species'] = species\n",
    "\n",
    "iris.sample(frac=1).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Accuracy: 96.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.97        43\n",
      "         1.0       1.00      0.91      0.95        32\n",
      "\n",
      "    accuracy                           0.96        75\n",
      "   macro avg       0.97      0.95      0.96        75\n",
      "weighted avg       0.96      0.96      0.96        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "perceptron = Perceptron(0.001, 100)\n",
    "\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "pred = perceptron.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(pred, y_test)\n",
    "report = classification_report(pred, y_test, digits=2)\n",
    "\n",
    "print(f'Perceptron Accuracy: {acc*100}%')\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa\n"
     ]
    }
   ],
   "source": [
    "prediction = perceptron.predict([[3.5, 1]])[0]\n",
    "\n",
    "if prediction == 0:\n",
    "    print(\"setosa\")\n",
    "elif prediction == 1:\n",
    "    print('versicolor')\n",
    "else:\n",
    "    print('virginica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Atlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
